## Python data-service standards

### Runtime, packaging, and tooling
- **Python 3.11+ only**: Pin the project to Python 3.11 (or later) in `pyproject.toml`/`runtime.txt` and configure CI to enforce the same version
- **Single dependency manager**: Standardize on `uv` for dependency/env management and script execution; do not mix with `pip` or Poetry unless an exception is documented
- **Pyproject-first**: Define dependencies, scripts, and tool settings in `pyproject.toml`; avoid ad-hoc `requirements.txt` except for deployment export
- **Formatting & linting**: Run `black`, `ruff`, and `isort` via `pre-commit` hooks; keep `ruff` as the single source of truth for lint configuration
- **Type checking**: Enable type hints everywhere and run `pyright` (or `mypy` if pyright unavailable) in CI; fail the build on implicit `Any`

### Configuration & secrets
- **.env loading**: Store local-only secrets in `.env` files and load them via `python-dotenv` early in the process bootstrap
- **Pydantic settings**: Use `pydantic`/`BaseSettings` classes to centralize configuration, validate env vars, and provide defaults
- **Twelve-factor friendly**: Never commit `.env` or raw credentials; document required env vars in README and sample env files

### Ingestion & HTTP clients
- **Requests session wrapper**: Expose a single `requests.Session` factory that sets retries/backoff, timeouts, auth headers, and telemetry
- **Parsers**: Use `beautifulsoup4` with the `lxml` parser for HTML; create extractor utilities that return typed `pydantic` models
- **Rate limiting**: Respect upstream quotas by baking sleep/retry logic into the client helper rather than scattering `time.sleep`
- **Auditability**: Log each fetch with target URL, response status, and correlation ID via `loguru`

### Data processing & graph modeling
- **Pandas pipelines**: Keep ETL steps in composable functions that accept/return DataFrames; document schema expectations via `pyarrow.Schema` or docstrings
- **Column contracts**: Normalize column names to `snake_case`, store dtypes explicitly (`df.astype`) before persistence, and assert on row counts after merges
- **NumPy usage**: Pull heavy numerical work into vectorized NumPy helpers; avoid Python loops for transforms over >10k rows
- **Network analysis**: Model graph operations with `networkx`, keeping raw nodes/edges as DataFrames and only materializing graphs inside analysis modules

### Database & modeling
- **Driver choice**: Use `psycopg2-binary` for synchronous access; wrap connections with SQLAlchemyâ€™s `create_engine` for pooling and retries
- **SQLAlchemy ORM**: Define models with declarative base, include `__tablename__`, indexes, and typed columns; keep alembic autogenerate clean
- **Migrations**: Use Alembic for schema changes, run `alembic upgrade/downgrade` locally before PRs, and follow expand/backfill/contract rules
- **Data validation**: Convert inbound/outbound DB payloads through `pydantic` models to keep API/data contracts aligned

### API layer (FastAPI)
- **Project layout**: Separate routers, schemas, services, and repositories; avoid putting DB calls inside route handlers
- **Pydantic schemas**: Version response/request models, add `ConfigDict(from_attributes=True)` for ORM compatibility, and reuse them in clients
- **Uvicorn config**: Run with `uvicorn[standard]` default workers, structured logging, and lifespan events for DB startup/shutdown
- **OpenAPI discipline**: Keep the autogenerated docs clean (no untyped responses) and publish `/openapi.json` with contract tests

### Dashboard & visualization
- **Streamlit as MVP**: Keep dashboards in `/apps/streamlit/*` modules; load data via shared repositories rather than re-querying ad hoc
- **Plot libraries**: Prefer Plotly for interactive charts; fall back to Matplotlib only for static exports
- **State management**: Cache expensive computations with `st.cache_data` and document cache invalidation triggers

### Orchestration & scheduling
- **Prefect flows**: Wrap ETL/jobs as Prefect flows with parameterized runs; define schedules and concurrency limits in code, not the UI
- **Local CLI parity**: Every Prefect flow should also be runnable via a CLI entry point for debugging without the orchestration layer
- **Observability**: Emit task run metadata (start/end timestamps, row counts) to logging to simplify backfills and audits

### Logging, testing, and automation
- **Loguru logger**: Initialize `loguru` once with JSON sinks for production and human-readable output locally; inject request/job context via `bind`
- **Pytest**: Use `pytest` with fixtures for DB/session setup, `pytest-vcr` (optional) for HTTP replay, and enforce coverage on critical modules
- **External systems**: Prefer dockerized Postgres/Redis for tests; mock only when the dependency is unstable or license-restricted
- **Pre-commit**: Enable `black`, `ruff`, `isort`, `pyright`, and `pytest --maxfail=1 --ff` (optional) in `.pre-commit-config.yaml` to catch issues before CI
